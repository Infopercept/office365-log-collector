# Production Configuration - Office365 Audit Log Collector
enabled: true

# DAEMON MODE - Runs continuously, fetches every 5 minutes
interval: "5m"  # Collection interval: "5m", "10m", "1h", etc.

# Only collect NEW events (don't fetch historical data on startup)
only_future_events: true

# Directory for state files
workingDir: "/var/lib/office365-collector"

# Your Office365 credentials
tenants:
  - tenant_id: "YOUR-TENANT-ID"
    client_id: "YOUR-CLIENT-ID"
    client_secret: "YOUR-CLIENT-SECRET"
    api_type: "commercial"

# Subscribe to all 5 main feeds
subscriptions:
  - "Audit.AzureActiveDirectory"
  - "Audit.Exchange"
  - "Audit.SharePoint"
  - "Audit.General"
  - "DLP.All"

# PRODUCTION: File output (Recommended - low memory, works with any log shipper)
output:
  file:
    path: "/var/log/office365/audit.json"
    separateByContentType: true  # Creates 5 separate files by content type

  # ALTERNATIVE: Fluentd output (if you need Fluentd specifically)
  # fluentd:
  #   tenantName: "MyCompany"
  #   address: "localhost"  # or "fluentd" if using Docker
  #   port: 24224

  # ALTERNATIVE: Graylog output
  # graylog:
  #   address: "graylog.example.com"
  #   port: 12201

log:
  path: ""  # Empty = stdout (for journalctl)
  debug: false

# Optional: Advanced performance tuning
# collect:
#   cacheSize: 500000   # LRU cache size for deduplication
#   maxThreads: 50      # Parallel download threads
#   retries: 3          # API retry attempts
